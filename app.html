<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Image Classifier</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 20px; }
    .wrap { max-width: 680px; margin: 0 auto; }
    .preview { display: grid; gap: 12px; margin-top: 16px; }
    #label { font-weight: 600; font-size: 1.1rem; }
    #prob { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }
    img, canvas { max-width: 100%; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,.12); }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: center; }
    button, input[type=file] { padding: 8px 12px; border-radius: 10px; border: 1px solid #ddd; background: #fff; cursor: pointer; }
  </style>
</head>
<body>
  <div class="wrap">
    <a href="index.html">← Home</a>
    <h1>Image Classifier</h1>
    <p>Pick a photo or use your camera; the model will predict <em>Fruit</em> vs <em>Vegetable</em>.</p>

    <div class="row">
      <input id="file" type="file" accept="image/*" />
      <button id="cameraBtn">Use Camera</button>
      <button id="stopBtn" disabled>Stop Camera</button>
    </div>

    <div class="preview">
      <video id="video" playsinline autoplay muted style="display:none;"></video>
      <canvas id="canvas" width="320" height="320" aria-label="preview"></canvas>
      <div id="label">Label: —</div>
      <div id="prob">Confidence: —</div>
    </div>
  </div>

  <!-- TFJS + Teachable Machine (versions compatible with your model) -->
  <script src="https://unpkg.com/@tensorflow/tfjs@1.7.4/dist/tf.min.js"></script>
  <script src="https://unpkg.com/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>

  <script>
    const MODEL_URL = './tm-model/'; // where model.json/metadata.json/weights.bin live
    const SIZE = 96;                 // from your model metadata (96x96 grayscale) 
    // (Your metadata also lists labels: Fruit, Vegetable.) 

    let model, webcamStream = null;

    const fileInput = document.getElementById('file');
    const cameraBtn = document.getElementById('cameraBtn');
    const stopBtn = document.getElementById('stopBtn');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const labelEl = document.getElementById('label');
    const probEl = document.getElementById('prob');

    async function loadModel() {
      // tmImage.load() reads model.json and metadata.json in the same folder
      model = await tmImage.load(MODEL_URL + 'model.json', MODEL_URL + 'metadata.json');
    }

    function drawToCanvas(srcEl) {
      const w = canvas.width, h = canvas.height;
      ctx.drawImage(srcEl, 0, 0, w, h);
    }

    async function predictFromCanvas() {
      if (!model) return;
      // tmImage expects an HTML element (canvas/video/img)
      const preds = await model.predict(canvas);
      // find top result
      preds.sort((a,b) => b.probability - a.probability);
      const top = preds[0];
      labelEl.textContent = 'Label: ' + top.className;
      probEl.textContent = 'Confidence: ' + (top.probability*100).toFixed(1) + '%';
    }

    fileInput.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      const img = new Image();
      img.onload = async () => {
        drawToCanvas(img);
        await predictFromCanvas();
      };
      img.src = URL.createObjectURL(file);
    });

    cameraBtn.addEventListener('click', async () => {
      try {
        webcamStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
        video.srcObject = webcamStream;
        video.style.display = 'block';
        video.onloadedmetadata = () => video.play();
        // draw video frames to canvas and predict periodically
        const tick = async () => {
          if (!webcamStream) return;
          drawToCanvas(video);
          await predictFromCanvas();
          requestAnimationFrame(tick);
        };
        tick();
        stopBtn.disabled = false;
      } catch (err) {
        alert('Camera error: ' + err.message);
      }
    });

    stopBtn.addEventListener('click', () => {
      if (webcamStream) {
        webcamStream.getTracks().forEach(t => t.stop());
        webcamStream = null;
        video.style.display = 'none';
        stopBtn.disabled = true;
      }
    });

    loadModel();
  </script>
</body>
</html>
